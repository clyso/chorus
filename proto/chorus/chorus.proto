syntax = "proto3";

package chorus;

import "google/protobuf/duration.proto";
import "google/protobuf/empty.proto";
import "google/protobuf/timestamp.proto";

option go_package = "github.com/clyso/chorus/proto/chorus;pb";

service Chorus {
  // Get app version
  rpc GetAppVersion(google.protobuf.Empty) returns (GetAppVersionResponse);

  // Lists configured storages with users
  rpc GetStorages(google.protobuf.Empty) returns (GetStoragesResponse);
  // Returns connection details for proxy s3 endpoint
  rpc GetProxyCredentials(google.protobuf.Empty) returns (GetProxyCredentialsResponse);

  // Returns list of buckets to configure new replication.
  rpc ListBucketsForReplication(ListBucketsForReplicationRequest) returns (ListBucketsForReplicationResponse);
  // Configures new replication for user or bucket(-s)
  rpc AddReplication(AddReplicationRequest) returns (google.protobuf.Empty);
  // Lists configured replications with statuses
  rpc ListReplications(google.protobuf.Empty) returns (ListReplicationsResponse);
  rpc ListUserReplications(google.protobuf.Empty) returns (ListUserReplicationsResponse);

  rpc StreamBucketReplication(ReplicationRequest) returns (stream Replication);

  // Pauses given replication
  rpc PauseReplication(ReplicationRequest) returns (google.protobuf.Empty);
  // Resumes given replication
  rpc ResumeReplication(ReplicationRequest) returns (google.protobuf.Empty);
  // Deletes given replication
  rpc DeleteReplication(ReplicationRequest) returns (google.protobuf.Empty);
  rpc DeleteUserReplication(DeleteUserReplicationRequest) returns (google.protobuf.Empty);

  // Switch main<->follower for selected replication without downtime.
  // Switch will be started immediately. It will route all writes to new main bucket and resolve reads to bucket with the latest data without blocking. When all replication tasks will be processed, switch will be completed and all reads and writes will be routed to new bucket. Unlike switch with downtime, switch without downtime is not checking bucket contents on completion and cannot be aborted or reverted without risk of data loss.
  // Method will return error in following cases:
  //   - there is no existing bucket replication
  //   - there are multiple replications from the same main bucket to multiple followers
  //   - switch already exists. Zero downtime switch cannot be updated. Use DeleteBucketSwitch in this case.
  //   - replication is to different bucket name. Will be supported later.
  rpc SwitchBucketZeroDowntime(SwitchBucketZeroDowntimeRequest) returns (google.protobuf.Empty);

  // Switch main<->follower for selected replication with downtime.
  // This method Can also be used to update existing switch if it has not started yet.
  // Workflow: stops write requests to bucket on chorus proxy until all replication tasks will be processed.
  // Then it checks if main and follower bucket contents are the same, unblocks writes, and routes all requests to follower bucket. If bucket contents are different, switch will be aborted and writes will be unblocked. Downtime Switch can be aborted or reverted without risk of data loss.
  // Method will return error in following cases:
  //   - there is no existing bucket replication
  //   - there are multiple replications from the same main bucket to multiple followers
  //   - switch is in progress - aka writes already blocked. Use DeleteBucketSwitch in this case.
  //   - switch is successfully finished
  //   - replication is to different bucket name. Will be supported later.
  rpc SwitchBucket(SwitchBucketRequest) returns (google.protobuf.Empty);

  // Deletes Switch with following implications:
  // !!!Use with caution for ZeroDowntime switch.
  // - If switch was in not_started, error, or skipped state, it will not be attempted anymore.
  //   proxy will route all requests to old bucket.
  // - If switch was in progress, it will be aborted. For downtime switch, bucket block will be removed
  //   proxy will route all requests to old bucket, no data will be lost.
  //   !!!For ZeroDowntime switch, routing will be reverted back to old bucket.
  //   Old and new buckets may end up in inconsistent state because all object writes happened
  //   since start of no_downtime migration were routed only to new bucket.
  // - If switch was done. Only switch metadata will be removed, replication or routing will not be affected.
  rpc DeleteBucketSwitch(ReplicationRequest) returns (google.protobuf.Empty);

  // Returns Switch status
  rpc GetBucketSwitchStatus(ReplicationRequest) returns (GetBucketSwitchStatusResponse);

  // returns list of all switches
  rpc ListReplicationSwitches(google.protobuf.Empty) returns (ListSwitchResponse);

  // Compares contents of given bucket in given storages
  rpc CompareBucket(CompareBucketRequest) returns (CompareBucketResponse);

  rpc GetAgents(google.protobuf.Empty) returns (GetAgentsResponse);

  rpc AddBucketReplication(AddBucketReplicationRequest) returns (google.protobuf.Empty);

  rpc GetReplication(ReplicationRequest) returns (Replication);

  rpc StartConsistencyCheck(ConsistencyCheckRequest) returns (google.protobuf.Empty);
  rpc ListConsistencyChecks(google.protobuf.Empty) returns (ListConsistencyChecksResponse);
  rpc GetConsistencyCheckReport(ConsistencyCheckRequest) returns (GetConsistencyCheckReportResponse);
  rpc GetConsistencyCheckReportEntries(GetConsistencyCheckReportEntriesRequest) returns (GetConsistencyCheckReportEntriesResponse);
  rpc DeleteConsistencyCheckReport(ConsistencyCheckRequest) returns (google.protobuf.Empty);
}

message MigrateLocation {
  string storage = 1;
  string bucket = 2;
  string user = 3;
}

message ConsistencyCheckRequest {
  repeated MigrateLocation locations = 1;
}

message ConsistencyCheck {
  string id = 1;
  repeated MigrateLocation locations = 2;
  uint64 queued = 3;
  uint64 completed = 4;
  bool ready = 5;
  bool consistent = 6;
}

message ListConsistencyChecksResponse {
  repeated ConsistencyCheck checks = 1;
}

message GetConsistencyCheckReportRequest {
  repeated MigrateLocation locations = 1;
}

message GetConsistencyCheckReportResponse {
  ConsistencyCheck check = 1;
}

message ConsistencyCheckReportEntry {
  string object = 1;
  string etag = 2;
  repeated string storages = 3;
}

message GetConsistencyCheckReportEntriesRequest {
  repeated MigrateLocation locations = 1;
  uint64 Cursor = 2;
  int64 PageSize = 3;
}

message GetConsistencyCheckReportEntriesResponse {
  repeated ConsistencyCheckReportEntry entries = 1;
  uint64 Cursor = 2;
}

message GetAppVersionResponse {
  string version = 1;
  string commit = 2;
  string date = 3;
}

message GetStoragesResponse {
  repeated Storage storages = 1;
}

message Storage {
  enum Provider {
    Other = 0;
    Ceph = 1;
    Minio = 2;
    AWS = 3;
    GCS = 4;
    Alibaba = 5;
    Cloudflare = 6;
    DigitalOcean = 7;
  }
  // some human-readable alias for storage config
  string name = 1;
  bool is_main = 2;
  // ex: s3.clyso.com
  string address = 3;
  // s3 storage provider <Ceph|Minio|AWS|Other>
  Provider provider = 4;
  // credentials: access key (public, aka username)
  repeated Credential credentials = 5;
}

message Credential {
  string alias = 1;
  string access_key = 2;
  string secret_key = 3;
}

message GetProxyCredentialsResponse {
  string address = 1;
  repeated Credential credentials = 2;
}

message AddReplicationRequest {
  string user = 1;
  string from = 3;
  string to = 4;
  repeated string buckets = 5;
  bool is_for_all_buckets = 6;
  optional string agent_url = 7;
  string to_bucket = 8;
}

message AddBucketReplicationRequest {
  // s3 user alias from chorus config
  string user = 1;
  // source storage alias from chorus config
  string from_storage = 2;
  // source bucket name
  string from_bucket = 3;
  // destination storage name from chorus config. Can be equal to destination storage if destination bucket name is different from source.
  string to_storage = 4;
  // custom destination bucket name. if not set, destination bucket name will be equal to source bucket
  string to_bucket = 5;
  // webhook URL of chorus agent. Required if chorus agent setup is used.
  optional string agent_url = 6;
}

message ListBucketsForReplicationRequest {
  string user = 1;
  string from = 2;
  string to = 3;
  bool show_replicated = 4;
}

message ListBucketsForReplicationResponse {
  repeated string buckets = 1;
  repeated string replicated_buckets = 2;
}

message ListReplicationsResponse {
  repeated Replication replications = 1;
}

message Replication {
  string user = 1;
  string bucket = 2;
  string from = 3;
  string to = 4;

  google.protobuf.Timestamp created_at = 5;
  bool is_paused = 6;
  bool is_init_done = 7;

  int64 init_obj_listed = 8;
  int64 init_obj_done = 9;

  int64 init_bytes_listed = 10;
  int64 init_bytes_done = 11;

  int64 events = 12;
  int64 events_done = 13;

  google.protobuf.Timestamp last_emitted_at = 14;
  google.protobuf.Timestamp last_processed_at = 15;

  optional string agent_url = 16;

  string to_bucket = 17;

  google.protobuf.Timestamp init_done_at = 18;

  // true if given replication has associated replication switch with it.
  bool has_switch = 19;
  // true if replication is archived. Archived replication will not generate or sync new events.
  // The main purpose of archived replication is to keep replication metadata for future reference.
  // Archived replication can be safely deleted.
  bool is_archived = 20;
  google.protobuf.Timestamp archived_at = 21;
}

message ReplicationRequest {
  string user = 1;
  string bucket = 2;
  string from = 3;
  string to = 4;
  string to_bucket = 5;
}

message ListUserReplicationsResponse {
  repeated UserReplication replications = 1;
}

message UserReplication {
  string user = 1;
  string from = 2;
  string to = 3;
}

message DeleteUserReplicationRequest {
  string user = 1;
  string from = 2;
  string to = 3;
  bool delete_bucket_replications = 4;
}

message CompareBucketRequest {
  string user = 1;
  string bucket = 2;
  string from = 3;
  string to = 4;
  // set true to get list of matching files (match) in response
  bool show_match = 5;
  string to_bucket = 6;
}

message CompareBucketResponse {
  // true if storage's buckets have the same content
  bool is_match = 1;
  // list of missing files in 'from storage' bucket
  repeated string miss_from = 2;
  // list of missing files in 'to storage' bucket
  repeated string miss_to = 3;
  // list of files with different content
  repeated string differ = 4;
  // list of errors occurred during comparison
  repeated string error = 5;

  // list matched files in storages bucket.
  // will be empty if request parameter show_match set to false.
  repeated string match = 6;
}

message GetAgentsResponse {
  repeated Agent agents = 1;
}

message Agent {
  string storage = 1;
  string url = 2;
}

message SwitchBucketZeroDowntimeRequest {
  // Id of bucket replication policy to switch source and destination buckets on proxy.
  // Replication policy should already exist.
  ReplicationRequest replication_id = 1;

  // Max Amount of time to wait for uncompleted multipart uploads to finish before switching buckets.
  // Default is 1 hour.
  optional google.protobuf.Duration multipart_ttl = 2;
}

message SwitchBucketRequest {
  // Id of bucket replication policy to switch source and destination buckets on proxy.
  // Replication policy should already exist.
  ReplicationRequest replication_id = 1;

  // Configures downtime window for switch. During downtime bucket writes will be blocked on proxy.
  // If NOT set, switch will be performed right away and writes will be blocked until it is done.
  optional SwitchDowntimeOpts downtime_opts = 2;
}

// Defines downtime window for replication switch with downtime.
// All dates and times depends on local times of machine running chorus worker.
// Time precision is ~1 minute.
message SwitchDowntimeOpts {
  // If true, chorus will perform switch automatically when initial migration will be done.
  // Initial migration copies all objects that existed in source bucket before replication started.
  // default is false
  bool start_on_init_done = 1;

  // If set, chorus will try or retry to execute switch according to CRON schedule until it will be done.
  // Bucket check and draining work queue is time consuming operation
  // so in most cases it is not makes sense to set cron frequency less than one hour
  // or less than max_duration if used.
  // Either cron or start_at can be set, but not both. If both are set, an error will be returned.
  optional string cron = 2;

  // If set, switch will be executed at given time.
  // If at this point initial migration will not be done, switch will be marked as failed and not executed.
  // Either cron or start_at can be set, but not both. If both are set, an error will be returned.
  optional google.protobuf.Timestamp start_at = 3;

  // If set, chorus will abort switch if it will not be able to complete in given time.
  // In this case, chorus will unblock bucket writes and keep old main as main.
  // Switch will be marked as failed and will be retried on next cron execution if set.
  optional google.protobuf.Duration max_duration = 4;

  // If set, switch execution will be skipped if number of unprocessed events is more than max_event_lag.
  // Switch will be marked as failed and will be retried on next cron execution if set.
  optional uint32 max_event_lag = 5;

  // if true, chorus will not perform equality check of bucket contents before completing switch with downtime.
  // Might be useful for buckets with large number of objects. In this case check will consume a lot of time and memory in Redis.
  // Default is false.
  bool skip_bucket_check = 6;

  // Set true to replicate data updates from new main to old main bucket after successful switch
  // Default is false.
  bool continue_replication = 7;
}

message GetBucketSwitchStatusResponse {
  enum Status {
    // Switch is not started yet
    NotStarted = 0;
    // Switch is in progress. Draining replication events queue.
    // For switch with downtime, writes to bucket are blocked at this point.
    InProgress = 1;
    // Switch is in progress. Queue is drained. Checking if main and follower buckets are the same.
    // Writes to bucket are still blocked. Used only for switch with downtime.
    CheckInProgress = 2;
    // Switch failed to complete in downtime window and was aborted.
    // Writes to bucket are unblocked. Used only for switch with downtime.
    // If cron downtime_window is used, switch will be retried on next cron execution.
    Error = 3;
    // Switch was not able to start in given downtime window because conditions were not met.
    // Used only for switch with downtime. If cron downtime_window is used, switch will be retried on next cron execution.
    Skipped = 4;
    // Switch was successfully completed.
    // All data was replicated to new main bucket and all read and write requests are now routed to it.
    Done = 5;
  }

  // Current switch status
  Status last_status = 1;
  // true if switch is zero downtime
  bool zero_downtime = 2;
  // multipart uploads TTL for zero downtime switch
  optional google.protobuf.Duration multipart_ttl = 3;
  optional SwitchDowntimeOpts downtime_opts = 4;

  // Time of last switch attempt - last time when switch was moved to InProgress status.
  optional google.protobuf.Timestamp last_started_at = 5;
  // Time of last switch completion. Set only if switch status is Done.
  optional google.protobuf.Timestamp done_at = 6;
  // History of switch status changes
  repeated string history = 7;

  ReplicationRequest replication_id = 8;
}

message ListSwitchResponse {
  repeated GetBucketSwitchStatusResponse switches = 1;
}
